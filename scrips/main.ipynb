{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "readdone\n",
      "66\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import process_json as pj\n",
    "\n",
    "#must use relative path\n",
    "#ipython's default path is different from python's\n",
    "#要解决数据不均衡的问题：半夜比中午少\n",
    "filename_night1 = \"../201206_tweets/activities_201206100000_201206100010.json\"\n",
    "filename_night2 = \"../201206_tweets/activities_201206100010_201206100020.json\"\n",
    "filename_night3 = \"../201206_tweets/activities_201206100020_201206100030.json\"\n",
    "filename_night4 = \"../201206_tweets/activities_201206100030_201206100040.json\"\n",
    "filename_night5 = \"../201206_tweets/activities_201206100040_201206100050.json\"\n",
    "filename_night6 = \"../201206_tweets/activities_201206100050_201206100100.json\"\n",
    "filename_night7 = \"../201206_tweets/activities_201206100100_201206100110.json\"\n",
    "filename_night8 = \"../201206_tweets/activities_201206100110_201206100120.json\"\n",
    "filename_night9 = \"../201206_tweets/activities_201206100120_201206100130.json\"\n",
    "filename_night10 = \"../201206_tweets/activities_201206100130_201206100140.json\"\n",
    "filename_night11 = \"../201206_tweets/activities_201206100140_201206100150.json\"\n",
    "filename_night12 = \"../201206_tweets/activities_201206100150_201206100200.json\"\n",
    "filename_night13 = \"../201206_tweets/activities_201206100200_201206100210.json\"\n",
    "filename_night14 = \"../201206_tweets/activities_201206100210_201206100220.json\"\n",
    "filename_night15 = \"../201206_tweets/activities_201206100220_201206100230.json\"\n",
    "filename_night16 = \"../201206_tweets/activities_201206100230_201206100240.json\"\n",
    "filename_night17 = \"../201206_tweets/activities_201206100240_201206100250.json\"\n",
    "filename_night18 = \"../201206_tweets/activities_201206100250_201206100300.json\"\n",
    "\n",
    "filename_day1 = \"../201206_tweets/activities_201206101200_201206101210.json\"\n",
    "filename_day2 = \"../201206_tweets/activities_201206101210_201206101220.json\"\n",
    "filename_day3 = \"../201206_tweets/activities_201206101220_201206101230.json\"\n",
    "filename_day4 = \"../201206_tweets/activities_201206101230_201206101240.json\"\n",
    "filename_day5 = \"../201206_tweets/activities_201206101240_201206101250.json\"\n",
    "filename_day6 = \"../201206_tweets/activities_201206101250_201206101300.json\"\n",
    "filename_day7 = \"../201206_tweets/activities_201206101300_201206101310.json\"\n",
    "filename_day8 = \"../201206_tweets/activities_201206101310_201206101320.json\"\n",
    "filename_day9 = \"../201206_tweets/activities_201206101320_201206101330.json\"\n",
    "filename_day10 = \"../201206_tweets/activities_201206101330_201206101340.json\"\n",
    "filename_day11 = \"../201206_tweets/activities_201206101340_201206101350.json\"\n",
    "filename_day12 = \"../201206_tweets/activities_201206101350_201206101400.json\"\n",
    "json_processor = pj.process_json()\n",
    "papers_night = []\n",
    "papers_night = json_processor.read_single_file(filename_night1,papers_night)\n",
    "papers_night = json_processor.read_single_file(filename_night2,papers_night)\n",
    "papers_night = json_processor.read_single_file(filename_night3,papers_night)\n",
    "papers_night = json_processor.read_single_file(filename_night4,papers_night)\n",
    "papers_night = json_processor.read_single_file(filename_night5,papers_night)\n",
    "papers_night = json_processor.read_single_file(filename_night6,papers_night)\n",
    "papers_night = json_processor.read_single_file(filename_night7,papers_night)\n",
    "papers_night = json_processor.read_single_file(filename_night8,papers_night)\n",
    "papers_night = json_processor.read_single_file(filename_night9,papers_night)\n",
    "papers_night = json_processor.read_single_file(filename_night10,papers_night)\n",
    "papers_night = json_processor.read_single_file(filename_night11,papers_night)\n",
    "papers_night = json_processor.read_single_file(filename_night12,papers_night)\n",
    "papers_night = json_processor.read_single_file(filename_night13,papers_night)\n",
    "papers_night = json_processor.read_single_file(filename_night14,papers_night)\n",
    "papers_night = json_processor.read_single_file(filename_night15,papers_night)\n",
    "papers_night = json_processor.read_single_file(filename_night16,papers_night)\n",
    "papers_night = json_processor.read_single_file(filename_night17,papers_night)\n",
    "papers_night = json_processor.read_single_file(filename_night18,papers_night)\n",
    "json_processor.draw_geo(papers_night)\n",
    "papers_day = []\n",
    "papers_day = json_processor.read_single_file(filename_day1,papers_day)\n",
    "papers_day = json_processor.read_single_file(filename_day2,papers_day)\n",
    "papers_day = json_processor.read_single_file(filename_day3,papers_day)\n",
    "papers_day = json_processor.read_single_file(filename_day4,papers_day)\n",
    "papers_day = json_processor.read_single_file(filename_day5,papers_day)\n",
    "papers_day = json_processor.read_single_file(filename_day6,papers_day)\n",
    "papers_day = json_processor.read_single_file(filename_day7,papers_day)\n",
    "papers_day = json_processor.read_single_file(filename_day8,papers_day)\n",
    "papers_day = json_processor.read_single_file(filename_day9,papers_day)\n",
    "papers_day = json_processor.read_single_file(filename_day10,papers_day)\n",
    "papers_day = json_processor.read_single_file(filename_day11,papers_day)\n",
    "papers_day = json_processor.read_single_file(filename_day12,papers_day)\n",
    "json_processor.draw_geo(papers_day)\n",
    "\n",
    "papers = papers_day+papers_night\n",
    "print(len(papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 2)\n",
      "(42, 2)\n"
     ]
    }
   ],
   "source": [
    "#creat dataset\n",
    "from sklearn.preprocessing import minmax_scale,StandardScaler\n",
    "import numpy as np\n",
    "geos_day,geos_night,day_label,night_label = [],[],[],[]\n",
    "for line in papers_day:\n",
    "    geos_day.append(line[\"geo\"][\"coordinates\"])\n",
    "    day_label = day_label+[1]\n",
    "for line in papers_night:\n",
    "    geos_night.append(line[\"geo\"][\"coordinates\"])\n",
    "    night_label = night_label+[0]\n",
    "    \n",
    "geos_day = np.array(geos_day)\n",
    "geos_night = np.array(geos_night)\n",
    "day_label,night_label = np.row_stack(day_label),np.row_stack(night_label)\n",
    "print(geos_day.shape)\n",
    "print((geos_night.shape))\n",
    "\n",
    "percent = 0.8\n",
    "partition = int(geos_day.shape[0]*percent)\n",
    "train_x_d, train_y_d, val_x_d, val_y_d = geos_day[:partition],day_label[:partition], geos_day[partition:], day_label[partition:]\n",
    "\n",
    "percent = 0.8\n",
    "partition = int(geos_night.shape[0]*percent)\n",
    "train_x_n, train_y_n, val_x_n, val_y_n = geos_night[:partition],night_label[:partition], geos_night[partition:], night_label[partition:]\n",
    "\n",
    "train_x = np.vstack((train_x_d,train_x_n))\n",
    "train_y = np.vstack((train_y_d,train_y_n))\n",
    "val_x = np.vstack((val_x_d,val_x_n))\n",
    "val_y = np.vstack((val_y_d,val_y_n))\n",
    "\n",
    "#归一化\n",
    "#target must 0D or 1D\n",
    "train_y = train_y.squeeze()\n",
    "val_y = val_y.squeeze()\n",
    "train_x = minmax_scale(train_x)\n",
    "val_x = minmax_scale(val_x)\n",
    "# print(train_x.shape,train_y.shape,val_x.shape,val_y.shape)\n",
    "# print(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat dataset\n",
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class GeoDataset(Dataset):\n",
    "    #有可能一次处理一个trains[i]\n",
    "    def __init__(self, X, y=None):\n",
    "        self.data = torch.tensor(X)\n",
    "        \n",
    "        if y is not None:\n",
    "            self.label=torch.tensor(y)\n",
    "        else:\n",
    "            self.label = None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.label is not None:\n",
    "            return self.data[idx], self.label[idx]\n",
    "        else:\n",
    "            return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset and dataloader\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = GeoDataset(train_x, train_y)\n",
    "val_set = GeoDataset(val_x, val_y)\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) #only shuffle the training data\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (fc1): Linear(in_features=2, out_features=5, bias=True)\n",
      "  (fc2): Linear(in_features=5, out_features=5, bias=True)\n",
      "  (fc3): Linear(in_features=5, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#用 全连接神经网络 进行分辨\n",
    "#目标：输出三色，白天和黑夜重合的部分输出绿色\n",
    "# 首先要引入相关的包\n",
    "import torch\n",
    "# 引入torch.nn并指定别名\n",
    "import torch.nn as nn\n",
    "#打印一下版本\n",
    "torch.__version__\n",
    "import torch.nn.functional as F\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        # nn.Module子类的函数必须在构造函数中执行父类的构造函数\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1   = nn.Linear(2, 5)  \n",
    "        self.fc2   = nn.Linear(5, 5)  \n",
    "        self.fc3   = nn.Linear(5, 2)  \n",
    "    #正向传播 \n",
    "    def forward(self, x): \n",
    "        x = self.fc1(x) \n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc2(x) \n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.sigmoid(x) \n",
    "        return x\n",
    "\n",
    "net = Classifier()\n",
    "print(net)\n",
    "\n",
    "#check device\n",
    "def get_device():\n",
    "  return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# fix random seed\n",
    "def same_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  \n",
    "    np.random.seed(seed)  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "# Feel free to change the training parameters here.\n",
    "# fix random seed for reproducibility\n",
    "same_seeds(0)\n",
    "\n",
    "# get device \n",
    "device = get_device()\n",
    "print(f'DEVICE: {device}')\n",
    "\n",
    "# training parameters\n",
    "num_epoch = 20              # number of training epoch\n",
    "learning_rate = 0.1      # learning rate\n",
    "\n",
    "# the path where checkpoint saved\n",
    "model_path = './model.ckpt'\n",
    "\n",
    "# create model, define a loss function, and optimizer\n",
    "model = Classifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lanpokn/.local/lib/python3.6/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001/020] Train Acc: 0.365385 Loss: 0.705202 | Val Acc: 0.642857 loss: 0.680247\n",
      "saving model with acc 0.643\n",
      "[002/020] Train Acc: 0.634615 Loss: 0.691331 | Val Acc: 0.642857 loss: 0.671779\n",
      "[003/020] Train Acc: 0.634615 Loss: 0.669462 | Val Acc: 0.642857 loss: 0.663830\n",
      "[004/020] Train Acc: 0.634615 Loss: 0.646774 | Val Acc: 0.642857 loss: 0.645901\n",
      "[005/020] Train Acc: 0.634615 Loss: 0.618602 | Val Acc: 0.642857 loss: 0.616921\n",
      "[006/020] Train Acc: 0.634615 Loss: 0.615346 | Val Acc: 0.642857 loss: 0.573986\n",
      "[007/020] Train Acc: 0.711538 Loss: 0.576228 | Val Acc: 0.928571 loss: 0.428578\n",
      "saving model with acc 0.929\n",
      "[008/020] Train Acc: 0.769231 Loss: 0.586884 | Val Acc: 0.928571 loss: 0.404261\n",
      "[009/020] Train Acc: 0.769231 Loss: 0.590711 | Val Acc: 0.928571 loss: 0.409637\n",
      "[010/020] Train Acc: 0.750000 Loss: 0.499999 | Val Acc: 0.928571 loss: 0.391807\n",
      "[011/020] Train Acc: 0.750000 Loss: 0.517546 | Val Acc: 0.928571 loss: 0.390444\n",
      "[012/020] Train Acc: 0.788462 Loss: 0.531784 | Val Acc: 0.785714 loss: 0.492777\n",
      "[013/020] Train Acc: 0.692308 Loss: 0.576497 | Val Acc: 0.928571 loss: 0.425752\n",
      "[014/020] Train Acc: 0.788462 Loss: 0.531758 | Val Acc: 0.928571 loss: 0.385631\n",
      "[015/020] Train Acc: 0.750000 Loss: 0.545249 | Val Acc: 0.928571 loss: 0.386894\n",
      "[016/020] Train Acc: 0.788462 Loss: 0.495694 | Val Acc: 0.857143 loss: 0.403954\n",
      "[017/020] Train Acc: 0.769231 Loss: 0.553125 | Val Acc: 0.785714 loss: 0.527585\n",
      "[018/020] Train Acc: 0.653846 Loss: 0.614452 | Val Acc: 0.785714 loss: 0.454319\n",
      "[019/020] Train Acc: 0.769231 Loss: 0.499558 | Val Acc: 0.928571 loss: 0.385287\n",
      "[020/020] Train Acc: 0.769231 Loss: 0.548566 | Val Acc: 0.928571 loss: 0.392391\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "#问题：交叉熵不要自己独热化，给0到n-1作为标签即可\n",
    "# 为了解决：expected scalar type Float but found Double\n",
    "model = model.double()\n",
    "#可能是因为没有初始化？\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight,std=0.01)\n",
    "model.apply(init_weights)\n",
    "\n",
    "best_acc = 0.0\n",
    "for epoch in range(num_epoch):\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    # training\n",
    "    model.train() # set the model to training mode\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # print(inputs),print(labels)\n",
    "        optimizer.zero_grad() \n",
    "        outputs = model(inputs) \n",
    "        # print(f'Train:{outputs}')\n",
    "        batch_loss = criterion(outputs, labels)\n",
    "        _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
    "        # print(f'train:{train_pred}')\n",
    "        batch_loss.backward() \n",
    "        optimizer.step() \n",
    "        \n",
    "        # print(train_pred.cpu())\n",
    "        train_acc += (train_pred.cpu() == labels.cpu()).sum().item()\n",
    "        train_loss += batch_loss.item()\n",
    "\n",
    "    # validation\n",
    "    if len(val_set) > 0:\n",
    "        model.eval() # set the model to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(val_loader):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                batch_loss = criterion(outputs, labels) \n",
    "                _, val_pred = torch.max(outputs, 1) \n",
    "            \n",
    "                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n",
    "                val_loss += batch_loss.item()\n",
    "\n",
    "            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n",
    "                epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader), val_acc/len(val_set), val_loss/len(val_loader)\n",
    "            ))\n",
    "\n",
    "            # if the model improves, save a checkpoint at this epoch\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print('saving model with acc {:.3f}'.format(best_acc/len(val_set)))\n",
    "    else:\n",
    "        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(\n",
    "            epoch + 1, num_epoch, train_acc/len(train_set), train_loss/len(train_loader)\n",
    "        ))\n",
    "\n",
    "# if not validating, save the last epoch\n",
    "if len(val_set) == 0:\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print('saving model at last epoch')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
